{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Filtracja Non-Local Means\n",
    "\n",
    "## Definicja\n",
    "\n",
    "Kolejny \"poziom wtajemniczenia\" w zagadnienie filtracji obrazów to metoda Non-Local Means (NLM).\n",
    "Została ona zaproponowana w pracy *\"A non-local algorithm for image denoising\"* (autorzy: Antoni Buades, Bartomeu Coll i Jean Michel Morel) na konferencji CVPR w 2005 roku.\n",
    "\n",
    "Filtr NLM dany jest zależnością:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{I}(\\mathbf{x}) = \\sum_{\\mathbf{p} \\in V(\\mathbf{x})} w(\\mathbf{p},\\mathbf{x})I(\\mathbf{p})\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "gdzie:\n",
    "- $I$ - obraz wejściowy,\n",
    "- $\\hat{I}$ - obraz wyjściowy (przefiltrowany),\n",
    "- $\\mathbf{x}$ - współrzędne piksela obrazu,\n",
    "- $V(\\mathbf{x})$ - obszar poszukiwań piksela, dla którego przeprowadzana jest filtracja,\n",
    "- $w$ - waga punktu $\\mathbf{p}$ z obszaru poszukiwań.\n",
    "\n",
    "Wróćmy na chwilę do filtracji bilateralnej. Tam waga danego piksela z kontekstu zależała od dwóch czynników - odległości przestrzennej pomiędzy pikselami oraz różnicy w jasności/kolorze pomiędzy pikselami (tzw. przeciwdziedzina).\n",
    "Filtr NLM stanowi uogólnienie tej metody - do obliczania wag nie wykorzystuje się już pojedynczych pikseli ($\\mathbf{p}$ i $\\mathbf{x}$), a lokalne konteksty ($N(\\mathbf{p})$ i $N(\\mathbf{x})$).\n",
    "\n",
    "Waga $w$ dana jest następującą zależnością:\n",
    "\n",
    "\\begin{equation}\n",
    "w(\\mathbf{p},\\mathbf{x}) = \\frac{1}{Z(\\mathbf{x})}\\exp(-\\frac{|| v(N(\\mathbf{p})) - v(N(\\mathbf{x})) ||^2_{2}}{\\alpha \\sigma^2})\n",
    "\\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "gdzie:\n",
    "\\begin{equation}\n",
    "Z(\\mathbf{x}) = \\sum_{\\mathbf{p} \\in V(\\mathbf{x})} \\exp(-\\frac{|| v(N(\\mathbf{p})) - v(N(\\mathbf{x})) ||^2_{2}}{\\alpha \\sigma^2})\n",
    "\\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "- $|| \\cdot ||$ - jest normą $L_2$ odległości pomiędzy dwoma kontekstami,\n",
    "- $v$ oznacza mnożenie punktowe kontekstu $N$ przez dwuwymiarową maskę Gaussa o odpowiadających kontekstowi wymiarach,\n",
    "- $\\alpha$ > 0 - parametr sterujący filtracją,\n",
    "- $\\sigma$ - parametr szumu stacjonarnego występującego na obrazie (w przypadku szumu niestacjonarnego, parametr $\\sigma$ musi zostać dopasowany lokalnie tj. $\\sigma = \\sigma(\\mathbf{x})$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza działania\n",
    "\n",
    "Zastanówmy sie teraz jak działa filtra NLM. Najprościej to zrozumieć na rysunku.\n",
    "\n",
    "![Ilustracja NLM](https://raw.githubusercontent.com/vision-agh/poc_sw/master/07_Bilateral/nlm.png)\n",
    "\n",
    "1. Dla rozważanego piksela $\\mathbf{x}$ definiujemy obszar poszukiwań $V(\\mathbf{x})$. Uwaga - obszar poszukiwań ($V$) jest jednostką większą niż otocznie/kontekst ($N$).\n",
    "\n",
    "2. Następnie, dla każdego z pikseli $\\mathbf{p} \\in  V(\\mathbf{x})$ oraz samego $\\mathbf{x}$ definiujemy otocznie/kontekst odpowiednio $N(\\mathbf{p})$ i $N(\\mathbf{x})$.\n",
    "\n",
    "3. Wracamy do równania definiującego wagę  $w(\\mathbf{p},\\mathbf{x})$, a konkretnie do wyrażenia $|| v(N(\\mathbf{p})) - v(N(\\mathbf{x})) ||$. Przeanalizujmy co ono oznacza. Mamy dwa otoczenia: $N(\\mathbf{p})$ i $N(\\mathbf{x})$. Każde z nich mnożymy przez odpowiadającą maskę Gaussa - funkcja $v$. Otrzymujemy dwie macierze, które odejmujemy od siebie punktowo. Następnie obliczamy kwadrat z normy ($L_2$ definiujemy jako $||X||_2 = \\sqrt{\\sum_k|X_k|^2}$. Otrzymujemy zatem jedną liczbę, która opisuje nam podobieństwo otoczeń pikseli $\\mathbf{x}$ i $\\mathbf{p}$. Mała wartość oznacza otoczenia zbliżone, duża - różniące się. Ponieważ, z dokładnością do stałych, liczba ta stanowi wykładnik funkcji $e^{-x}$, to ostatecznie waga jest zbliżona do 1 dla otoczeń podobnych, a szybko maleje wraz z malejącym podobieństwem kontekstów.\n",
    "\n",
    "4. Podsumowując: jak wynika z powyższej analizy filtr NLM to taki filtr bilateralny, w którym zamiast pojedynczych pikseli porównuje się ich lokalne otoczenia. Wpływa to pozytywnie na jakość filtracji, niestety kosztem złożoności obliczeniowej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Implementacja\n",
    "\n",
    "W ramach zadania należy zaimplementować filtr NLM, ocenić jego działanie w porównaniu do filtra Gaussa i bilateralnego oraz dokonać pomiaru czasu obliczeń (dla trzech wymienionych metod).\n",
    "\n",
    "Jak już się zrozumie jak działa NLM, jego implementacja jest dość prosta.\n",
    "Wartość parametru $\\alpha$ należy dobrać eksperymentalnie.\n",
    "Nie należy także \"przesadzić\" z rozmiarem obszaru poszukiwań (np. 11x11) oraz kontekstu (5x5 lub 3x3).\n",
    "\n",
    "Wskazówki do implementacji:\n",
    "- algorytm sprowadza się do dwóch podwójnych pętli for: zewnętrzne po pikselach, wewnętrzne po kolejnych obszarach przeszukań,\n",
    "- przed realizacją trzeba przemyśleć problem pikseli brzegowych - de facto problemów jest kilka. Po pierwsze nie dla każdego piksela można wyznaczyć pełny obszar przeszukań (tu propozycja, aby filtrację przeprowadzać tylko dla pikseli z pełnym obszarem). Po drugie, ponieważ rozpatrujemy konteksty, to nawet dla piksela o \"pełnym\" obszarze przeszukań, będą istnieć piksele, dla których nie pełnych kontekstów (sugestia - powiększyć obszar przeszukać, tak aby zawierał konteksty). Ostatni problem jest bardziej techniczny/implementacyjny. Jeśli w kolejnych iteracjach \"jawnie\" wytniemy fragment o rozmiarach obszaru przeszukiwań, to znowu pojawi się problem brzegowy - tu można albo wyciąć nieco większy obszar, albo cały czas \"pracować\" na obrazie oryginalnym (\"żonglerka indeksami\").\n",
    "- warto sprawdzać indeksy i rozmiary \"wycinanych\" kontekstów,\n",
    "- wagi wyliczamy w trzech krokach:\n",
    "    - obliczenia dla $N(\\mathbf{x})$ + inicjalizacja macierzy na wagi,\n",
    "    - podwójna pętla, w której przeprowadzamy obliczenia dla kolejnych $N(\\mathbf{p})$ oraz wyliczamy wagi,\n",
    "    - normalizacja macierzy wag oraz końcowa filtracja obszaru w wykorzystaniem wag.\n",
    "- uwaga, obliczenia trochę trwają, nawet dla obrazka 256x256 i względnie niewielkich obszaru przeszukań i kontesktu.\n",
    "\n",
    "Efekt końcowy:\n",
    "- porównanie wyników metod: filtr Gaussa, filtr bilateralny oraz filtr NLM (2-3 zdania komentarza),\n",
    "- porównanie czasu działania powyższych metod (1 zdanie komentarza).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import math\n",
    "import os\n",
    "import copy\n",
    "import cv2\n",
    "from scipy import signal\n",
    "from numpy import linalg \n",
    "import time\n",
    "\n",
    "\n",
    "if not os.path.exists(\"MR_data.mat\") :\n",
    "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/07_Bilateral/MR_data.mat --no-check-certificate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = loadmat('MR_data.mat')\n",
    "Input_0 = mat['I_noisefree']\n",
    "Input_1 = mat['I_noisy1']\n",
    "Input_2 = mat['I_noisy2']\n",
    "Input_3 = mat['I_noisy3']\n",
    "Input_4 = mat['I_noisy4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgaussian(size, sigma):\n",
    "    m = n = size\n",
    "    h, k = m // 2, n // 2\n",
    "    x, y = np.mgrid[-h:h+1, -k:k+1]\n",
    "    g = np.exp(-(x**2 + y**2)/(2*sigma**2))\n",
    "    return g /g.sum() \n",
    "\n",
    "def mesh(size, sigma):\n",
    "    m = n = size\n",
    "    h, k = m//2, n//2\n",
    "    x, y = np.mgrid[-h:h+1, -k:k+1]\n",
    "    g = np.exp(-(x**2 + y**2)/(2*sigma**2))\n",
    "    return g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wsp(okno, filtr, wariancja):\n",
    "    A,B = okno.shape\n",
    "    piksel = 0\n",
    "    x = [A // 2, B // 2]\n",
    "    for i in range(A):\n",
    "        for j in range(B):\n",
    "            AB = [i, j]\n",
    "            y = np.sqrt(((x[0] - i)**2) + ((x[1] - j)**2))\n",
    "            g = np.exp(-(y**2)/(2*(wariancja**2)))\n",
    "            piksel = piksel + g * okno[i, j]\n",
    "    piksel = piksel / filtr.sum()\n",
    "    return piksel\n",
    "\n",
    "\n",
    "def konwolucja(obraz, okno, wariancja):\n",
    "    filtr = mesh(5, wariancja)\n",
    "    IConv = obraz.copy()\n",
    "    (X,Y) = IConv.shape\n",
    "    polowa_okna = okno // 2\n",
    "    for i in range(0 + polowa_okna, X - polowa_okna):\n",
    "        for j in range(0 + polowa_okna, Y - polowa_okna):\n",
    "            okno = IConv[i - polowa_okna : i + polowa_okna + 1, j - polowa_okna : j + polowa_okna + 1]\n",
    "            new_pixel = wsp(okno, filtr, wariancja)\n",
    "            IConv[i, j] = new_pixel\n",
    "    return IConv\n",
    "\n",
    "\n",
    "def exp(y, sigma):\n",
    "  return np.exp(-(y*y/2*sigma*sigma))\n",
    "\n",
    "def gamma(tab, sigma, Ix):\n",
    "  tab_new = np.zeros((3, 3))\n",
    "  for i in range(len(tab)):\n",
    "    for j in range(len(tab[0])):\n",
    "      tab_new[i, j] = exp(abs(tab[i, j] - Ix), sigma)\n",
    "  return tab_new\n",
    "\n",
    "def wsp_2(okno, filtr, wariancja, delta_r):\n",
    "    A,B = okno.shape\n",
    "    piksel_2 = 0\n",
    "    normalizacja = 0\n",
    "    \n",
    "    tab = [A // 2, B // 2]\n",
    "    for i in range(A):\n",
    "        for j in range(B):\n",
    "            AB = [i, j]\n",
    "            \n",
    "            y = np.sqrt(((tab[0] - i)**2) + ((tab[1] - j)**2))\n",
    "            gauss = np.exp(-(y**2) / (2*(wariancja**2)))\n",
    "            \n",
    "            roznica = np.abs(okno[A // 2, B // 2] - okno[i, j])\n",
    "            gauss_roznica = np.exp(-(roznica**2) / (2*(delta_r**2)))\n",
    "            \n",
    "            piksel_2 = piksel_2 + gauss * gauss_roznica * okno[i, j]\n",
    "            normalizacja = normalizacja+(gauss * gauss_roznica)\n",
    "    piksel_2 = piksel_2 / normalizacja\n",
    "    return piksel_2\n",
    "        \n",
    "def bilateralna(obraz, okno, wariancja, delta_r):\n",
    "    filtr = mesh(okno, wariancja)\n",
    "    IConvol = obraz.copy()\n",
    "    (X,Y) = IConvol.shape\n",
    "    polowa_okna = okno//2\n",
    "    for i in range(0 + polowa_okna, X - polowa_okna):\n",
    "        for j in range(0 + polowa_okna, Y - polowa_okna):\n",
    "            okno = IConvol[i - polowa_okna : i + polowa_okna + 1, j - polowa_okna : j + polowa_okna + 1]\n",
    "            nowy_pixel = wsp_2(okno, filtr, wariancja, delta_r)\n",
    "            IConvol[i,j] = nowy_pixel\n",
    "    return IConvol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementacja filtra NML\n",
    "\n",
    "def NLM(obraz, okno, obszar, alfa, sigma):\n",
    "    \n",
    "    #Zdefiniowanie obszaru poszukiwan piksela\n",
    "    V = fgaussian(okno, np.sqrt(sigma))\n",
    "    \n",
    "    #Obraz wyjściwy\n",
    "    Obrazwyj = obraz.copy()\n",
    "    (X,Y) = Obrazwyj.shape\n",
    "    polowa_obszaru = obszar//2\n",
    "    polowa_okna = okno//2\n",
    "    \n",
    "    #Przejscie po pikselach oraz po obszarach przeszukiwan\n",
    "    for i in range(polowa_okna + polowa_obszaru, X - polowa_obszaru - polowa_okna):\n",
    "        for j in range(polowa_okna + polowa_obszaru, Y - polowa_obszaru - polowa_okna):\n",
    "            \n",
    "            i1 = i + polowa_obszaru + polowa_okna\n",
    "            i2 = i - polowa_obszaru - polowa_okna\n",
    "            j1 = j + polowa_obszaru + polowa_okna\n",
    "            j2 = j - polowa_obszaru - polowa_okna\n",
    "            \n",
    "            #definicja obrazu wejsciowego\n",
    "            nowy_obszar = obraz[i2 : i1, j2 : j1]\n",
    "            A, B = nowy_obszar.shape\n",
    "            \n",
    "            #Definicja zmiennych\n",
    "            zx = 0\n",
    "            wpx = 0\n",
    "            nowy_piksel = 0\n",
    "            \n",
    "            #wspolrzedne piksela\n",
    "            x = [i, j]\n",
    "            \n",
    "            \n",
    "            #podwojne petla dla kolejnych Np i wyliczenia wag\n",
    "            for a in range(polowa_okna, A - polowa_okna):\n",
    "                for b in range(polowa_okna, B - polowa_okna):\n",
    "                    \n",
    "                    #definicja otoczenia\n",
    "                    Np = nowy_obszar[a-polowa_okna:a+polowa_okna+1,b-polowa_okna:b+polowa_okna+1]\n",
    "                    \n",
    "                    #definicja kontekstu\n",
    "                    Nx = obraz[b-polowa_okna:b+polowa_okna+1,b-polowa_okna:b+polowa_okna+1]\n",
    "                    \n",
    "                    #Wymnożenie przez maskę Gaussa\n",
    "                    V1 = V*Np\n",
    "                    V2 = V*Nx\n",
    "                    \n",
    "                    #Odjęcie macierzy od siebie\n",
    "                    Xk = V1 - V2\n",
    "                    \n",
    "                    #Kwadrat z normy\n",
    "                    Xnorm = np.sqrt((Xk**2).sum())\n",
    "                    \n",
    "                    #Obliczenie wagi w(p,x)\n",
    "                    wpx = np.exp((-(Xnorm**2))/(alfa * sigma))\n",
    "                    \n",
    "                    zx = zx + wpx\n",
    "                    nowy_piksel = nowy_piksel + wpx * nowy_obszar[a, b]\n",
    "            \n",
    "            nowy_piksel = nowy_piksel / zx\n",
    "            \n",
    "            Obrazwyj[i, j] = nowy_piksel\n",
    "            \n",
    "    return Obrazwyj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zdefiniowanie parametrow\n",
    "okno = 6\n",
    "wariancja = 0.7\n",
    "delta_r = 33\n",
    "wariancja1 = 4\n",
    "\n",
    "#Obliczenie czasu dla konwulacji\n",
    "start_conv = time.time()\n",
    "konwolucja1 = konwolucja(Input_2, okno, wariancja)\n",
    "stop_conv = time.time()\n",
    "czas_conv = stop_conv - start_conv\n",
    "\n",
    "#Oblicenie czasu dla filtracji bilateralnej\n",
    "start_bilateralna = time.time()\n",
    "bilateralna1 = bilateralna(Input_2, okno, wariancja1, delta_r)\n",
    "stop_bilateralna = time.time()\n",
    "czas_bilateralna = stop_bilateralna - start_bilateralna\n",
    "\n",
    "#Obliczenie czasu dla filtracji NLM\n",
    "start_NLM = time.time()\n",
    "NLM1 = NLM(Input_2, 3, 8, 5, 45)\n",
    "stop_NLM = time.time()\n",
    "czas_NLM = stop_NLM - start_NLM\n",
    "\n",
    "print(\"Porównanie czasów:\")\n",
    "print(\"Konwolucja - {}\".format(czas_conv))\n",
    "print(\"Filtracja bilateralna - {}\".format(czas_bilateralna))\n",
    "print(\"Filtracja NLM - {}\".format(czas_NLM))\n",
    "\n",
    "f, ax = plt.subplots(2, 2, figsize = (16, 16))\n",
    "\n",
    "ax[0,0].imshow(Input_2, 'gray')\n",
    "ax[0,0].set_title(\"Oryginalny obraz\")\n",
    "ax[0,0].axis('off')\n",
    "\n",
    "ax[0,1].imshow(NLM1, 'gray')\n",
    "ax[0,1].set_title(\"Filtracja NLM\")\n",
    "ax[0,1].axis('off')\n",
    "\n",
    "ax[1,0].imshow(bilateralna1, 'gray')\n",
    "ax[1,0].set_title(\"Filtracja bilateralna\")\n",
    "ax[1,0].axis('off')\n",
    "\n",
    "ax[1,1].imshow(konwolucja1, 'gray')\n",
    "ax[1,1].set_title(\"Konwolucja\")\n",
    "ax[1,1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KOMENTARZ**   \n",
    "Podsumowując na podstawie powyższych obrazów możemy stwierdzić, iż najlepszy wynik otrzymaliśmy dla Filtracji NML.Metoda ta zdecydowanie wygrywa z filtracją Gaussa oraz filtracją bilateralną pod tym względem, że dla filtacji NML został zlikwiodowany szum oraz krawędzie są widoczne. Czasy działania filtracji Gaussa oraz bilateralnej są bradzo podobne natomiast dla filtracji NML ten czas jest zdecydowanie dłuższy oraz metoda ta wykorzystuje zdecydowanie więcej pamięci.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
