{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Segmentacja obrazów\n",
    "\n",
    "## Cel ćwiczenia\n",
    "- zapoznanie z metodami segmentacji obrazów:\n",
    "    - segmentacją przez rozrost obszaru (*region growing*)\n",
    "    - i w ramach zadania domowego segmentacją przez podział i łączenie (*split and merge*)\n",
    "\n",
    "## Wstęp\n",
    "\n",
    "W ramach dotychczas wykonanych ćwiczeń poznaliśmy segmentację z wykorzystaniem binaryzacji (progowania) - tj. na podstawie jasności (koloru) poszczególnych pikseli.\n",
    "Wykonaliśmy dwa warianty metody: globalny i lokalny oraz przetestowaliśmy różne podejścia do automatycznego wyznaczania progu bianryzacji (iteracyjne oraz Otsu).\n",
    "Ponadto poznaliśmy możliwość segmentacji na podstawie krawędzi z wykorzystaniem transformaty Hougha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podstawy\n",
    "\n",
    "Niech $R$ oznacza obszar równy całemu analizowanemu obrazowi.\n",
    "Segmentację możemy uznać za proces podziału $R$ na $n$ podobszarów $R_1,R_2,...,R_n$ takich że:\n",
    "1. $\\cup_{i=1}^n R_i = R$\n",
    "2. $R_i$ - składa się z połączonych ze sobą pikseli,\n",
    "3. $R_i \\cap R_j = \\varnothing $ dla wszystkich $i$ i $j$,$ i \\neq j$,\n",
    "4. $Q(R_i) = TRUE$ dla $i = 1,2,...n$\n",
    "5. $ Q(R_i \\cup R_j) = FALSE$ dla każdych sąsiednich $R_i$ i $R_j$.\n",
    "\n",
    "gdzie: symbole $\\cup$ i $\\cap$ oznaczają odpowiednio sumę i iloczyn zbiorów, a $Q$ jest pewnym predykatem.\n",
    "\n",
    "Punkt *1* oznacza, że segmentacja musi być kompletna tj. każdy piksel powinien zostać przyporządkowany do jakiegoś zbioru.\n",
    "\n",
    "Punkt *2* oznacza, że piksele w ramach jednego podobszaru muszą być ze sobą połączone (na zasadzie sąsiedztwa 4 lub 8 punktowego).\n",
    "\n",
    "Punkt *3* oznacza, że dowolne różne podobszary muszą być rozłączne.\n",
    "\n",
    "Punkt *4* oznacza, że wszystkie piksele będące w ramach jednego podobszaru muszą spełniać pewną własność. Przykładowo może to być ten sam lub podobny odcień szarości.\n",
    "\n",
    "Punkt *5* oznacza, że dwa sąsiednie podobszary muszą być różne w sensie predykatu Q (inaczej powinny zostać uznane za ten sam podobszar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentacja przez rozrost obszaru\n",
    "\n",
    "Pomysł jest następujący.\n",
    "Wybieramy (jak ? - o tym później) piksele startowe (ang. *seed*) i od nich zaczynamy segmentację.\n",
    "Odbywa się ona na zasadzie sprawdzania czy sąsiednie piksele (sąsiedztwo 4 lub 8 punktowe) są podobne do centralnego pod względem jakieś cechy (predykatu $Q$).\n",
    "Jeśli tak to oznaczane są jako należące do tej samej klasy co piksel centralny.\n",
    "Ponadto stają się one kolejnymi punktami startowymi metody.\n",
    "Zatem procedura ma charakter rekurencyjny.\n",
    "\n",
    "Wybór punktów startowych może być podyktowany charakterem problemu (przykładowo wiemy gdzie na pewno zaczynają się obiekty).\n",
    "W ogólnym przypadku trzeba założyć, że pikselem startowym może być każdy piksel, co oczywiście wpływa na złożoność metody.\n",
    "\n",
    "Kolejnym problemem jest wybór kryterium stopu tj. kiedy nasza procedura rekurencyjna ma się zakończyć.\n",
    "Dla danego podobszaru będzie to moment, kiedy nie istnieją już piksele, które można do  niego dołączyć.\n",
    "\n",
    "Warto w tym miejscu zwrócić uwagę, że stosowanie ''sztywnego'' warunku - np. różnica jasności pomiędzy pikselem centralnym, a analizowanym jest mniejsza niż 5 - może często dać niepożądane wyniki, gdyż nie uwzględnia pewnych lokalnych właściwości.\n",
    "Przykładowo, może się okazać, że jeśli na obrazie występuje niewielki gradient to za należące do tego samego obszaru uznane zostaną piksele o zupełnie różnych jasnościach.\n",
    "Możliwa jest też sytuacja odwrotna.\n",
    "Duże zróżnicowanie wartości na obrazie spowoduje zbyt duże ''poszarpanie'' wykrytych obszarów.\n",
    "\n",
    "Jednym z możliwych rozwiązań jest uzależnienie kryterium podobieństwa (predykatu $Q$) od własności obrazu np. średniej jasności w obrębie danego obszaru.\n",
    "Można również dodać inne kryteria np. kształt podobszaru itp.\n",
    "\n",
    "Uwaga. Pojęcie segmentacja przez rozrost to pewna **koncepcja** podejścia do segmentacji, a nie konkretna metoda.\n",
    "Na etapie projektowania algorytmu należy skupić się na konstrukcji kryterium podobieństwa (tj. co i jak ma być ze sobą porównywane) oraz ewentualnym uzupełnianiu metody o dodatkowe kryteria.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie: zaprojektować system segmentacji wybranej struktury na obrazie MRI (np. stawu kolanowego).\n",
    "Punkt startowy wyznaczany będzie ''ręcznie'' (poprzez kliknięcie na obrazie).\n",
    "\n",
    "1. Wczytaj obraz *knee.png* (w skali szarości) - MRI stawu kolanowego. Wyświetl go. Załóżmy, że chcemy dokonać segmentacji górnej kości. Przyjęliśmy, że punkt startowy metody wyznaczany będzie w sposób ręczny. Do pobrania położenia kursora myszy na ekranie służy funkcja `plt.ginput`. Uwaga. Jeśli obrazki są ''osadzone'' w notatniku, funkcja nie działa - proszę zwrócić uwagę na kod `matplotlib.use('TkAgg')`, który powoduje, że obrazki wyświetlane są ''samodzielnie''.\n",
    "\n",
    "  Uwaga 1. Pobrane współrzędne należy zaokrąglić (*floor* lub *round*).\n",
    "\n",
    "  Uwaga 2. Dla potrzeb testów dobrze jest wpisać punkt startowy na ''sztywno''. Pozwoli to uniknąć dość irytującego klikania przy każdym uruchomieniu skryptu.\n",
    "\n",
    "\n",
    "2. Metodę zaimplementujemy z wykorzystaniem stosu.\n",
    "   Uwaga. Podany poniżej opis jest tylko jedną z możliwych realizacji (niekoniecznie najlepszą).\n",
    "   Na początek tworzymy dwie macierze o rozmiarach takich jak analizowany obraz.\n",
    "   W jednej będziemy zapisywać odwiedzone lokalizacje (`visited` - typ *boolean*), a w drugiej rezultaty segmentacji (`segmented`).\n",
    "   Obie macierze tworzymy wypełnione zerami (funkcja `np.zeros`).\n",
    "   Tworzymy też stos - w Python to po prostu ''pusta lista''.\n",
    "\n",
    "3. W pierwszym kroku metody na stos (`stack.append`) odkładamy współrzędne wybranego przez użytkowania piksela.\n",
    "   Oznaczamy go również jako odwiedzony (macierz *visited*) i zaliczony do obiektu (macierz *segmented*).\n",
    "\n",
    "4. Pozostałe działanie odbywać się będzie w pętli `while`, której warunkiem stopu jest obecność elementów na stosie (`len(stack)>0`).\n",
    " W iteracji należy pobrać współrzędne piksela ze stosu.\n",
    "  Następnie sprawdzamy, czy dla tego piksela można określić kontekst o rozmiarze $ 3 \\times 3$ tj. czy ma wszystkich sąsiadów.\n",
    "  Uwaga. Przyjmujemy tutaj uproszczenie - nie segmentujemy brzegu obrazka (ramki o szerokości 1 piksela).\n",
    "\n",
    "5. W kolejnym kroku rozpisujemy pętlę po otoczeniu $3 \\times 3$ (x2 `for`).\n",
    "   Wewnątrz obliczamy odległość pomiędzy pikselem centralnym, a każdym z kontekstu.\n",
    "   Przyjmijmy, że będzie to moduł z różnicy jasności.\n",
    "   Jeśli wartość modułu będzie mniejsza od zdefiniowanego progu (proszę przyjąć jako początkową wartość 4) oraz rozpatrywany piksel nie był wcześniej odwiedzany to oznaczamy go jako należący do obiektu oraz jego współrzędne ''odkładamy'' na stosie.\n",
    "   Uwaga. Pierwsza część warunku logicznego to nasz predykat Q.\n",
    "   Za piksele podobne uznajemy takie, których różnica w jasności jest mniejsza niż zadany próg.\n",
    "   Niezależnie od wyniku testu oznaczamy piksel jako odwiedzony (żeby wielokrotnie nie analizować tych samych lokalizacji).\n",
    "\n",
    "6. Poza pętlą `while` proszę wyświetlić rezultat segmentacji.\n",
    "   Czy wyniki są poprawne ?\n",
    "   Proszę poeksperymentować z wartością progu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if not os.path.exists(\"knee.png\") :\n",
    "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/12_Segmentation/knee.png --no-check-certificate\n",
    "\n",
    "I_knee = cv2.imread('knee.png', cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "plt.imshow(I_knee, 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def segmentation_global(image, x, y, threshold=4):\n",
    "    X,Y = image.shape\n",
    "    #odwiedzone\n",
    "    visited = np.zeros(image.shape, dtype=np.uint64)\n",
    "    #segmentacja\n",
    "    segmented = np.zeros(image.shape, dtype=np.uint64)\n",
    "    #stos\n",
    "    stack = []\n",
    "    stack.append((x,y))\n",
    "    #odwiedzony\n",
    "    visited[x,y] = 1\n",
    "    segmented[x,y] = 1\n",
    "    #warunek obcności elementów na stosie\n",
    "    while len(stack) > 0:\n",
    "        #pobranie ze stosu\n",
    "        pkt = stack.pop()\n",
    "        x2 = pkt[0]\n",
    "        y2 = pkt[1]\n",
    "        \n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                #moduł z róznicy jasności\n",
    "                odl = np.abs(image[x2-1+i,y2-1+j] - image[x,y])\n",
    "            if (threshold > odl) and (visited[x2-1+i,y2-1+j] == 0):\n",
    "                stack.append((x2-1+i,y2-1+j))\n",
    "                segmented[x2-1+i,y2-1+j] = image[x2-1+i,y2-1+j]\n",
    "            visited[x2-1+i,y2-1+j] = 1\n",
    "         \n",
    "    return segmented        \n",
    "\n",
    "p1 = segmentation_global(I_knee,200, 250,60)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(7, 7)\n",
    "ax.imshow(p1, 'gray')\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "p2 = segmentation_global(I_knee,100, 50, 60)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(7, 7)\n",
    "ax.imshow(p2, 'gray')\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "p3 = segmentation_global(I_knee,300, 280, 60)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(7, 7)\n",
    "ax.imshow(p3, 'gray')\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "p4 = segmentation_global(I_knee,350, 200, 60)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(7, 7)\n",
    "ax.imshow(p4, 'gray')\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Komentarz\n",
    "#Wyniki wydają się być poprawne. Wybrany przeze mnie próg może skutkować tym, że w niektórych sytuacjach w zależności od \n",
    "#punktu startowego obrazek może być poszarpany."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Powyższy przykład ukazuje wspomniany wcześniej problem z ''globalnym'' podejściem do predykatu Q.\n",
    "  Jeśli próg będzie mały, to wyznaczymy jedynie niewielki fragment kości.\n",
    "  Natomiast zwiększenie progu skutkuje segmentacją nadmiarową.\n",
    "  Mówiąc kolokwialnie, na obrazie znajdzie się ''ścieżka'' po której możliwe jest przejście od obszaru jasnego do ciemnego nie ''łamiąc'' progu odległości pomiędzy sąsiednimi pikselami.\n",
    "\n",
    "2. Aby zaradzić powyższemu problemowi, można za kryterium podobieństwa przyjąć, nie różnicę jasności względem piksela centralnego, a od globalnie wyznaczonego i aktualizowanego progu.\n",
    "  W najprostszym przypadku może to być średnia jasność w wyznaczonym obszarze.\n",
    "  W celu implementacji mechanizmu wystarczy dodać dwie zmienne: średnią ($mV$) oraz licznik pikseli uznanych za należące do obiektu ($nS$).\n",
    "  Przy każdym zdjęciu ze stosu licznik jest zwiększany o 1.\n",
    "  Aktualizacja średniej następuje na podstawie równania:\n",
    "  \\begin{equation}\n",
    "  mV_{n} = \\frac{mV_{nS-1} (nS - 1) + I}{nS}\n",
    "  \\tag{1}\n",
    "  \\end{equation}\n",
    "  \n",
    "  Następnie wystarczy tylko zmienić sposób obliczania odległości - zamienić piksel centralny na wartość średnią.\n",
    "  Proszę spróbować jak działa metodą z taką modyfikacją - proszę się liczyć z koniecznością zwiększenia progu (nawet dość znaczną).\n",
    "\n",
    "3. Poprawić działanie metody może również dodanie filtracji uśredniającej np. filtrem Gaussa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "knee_1 = cv2.GaussianBlur(I_knee,(5,5),0)\n",
    "def segmentation_lokal(image, x, y, threshold = 4):\n",
    "  srednia = image[x,y]\n",
    "  srednia_n = 0\n",
    "  visited = np.zeros(image.shape)\n",
    "  segmented = np.zeros(image.shape)\n",
    "  stack = []\n",
    "  stack.append((x,y))\n",
    "  visited[x,y] = 1\n",
    "  segmented[x,y] = 1\n",
    "  while len(stack) > 0:\n",
    "    pkt = stack.pop()\n",
    "    x2 = pkt[0]\n",
    "    y2 = pkt[1]\n",
    "    if srednia_n != 0:\n",
    "        srednia = (srednia * (srednia_n-1) + image[x2,y2]) / srednia_n\n",
    "    srednia_n = srednia_n + 1;\n",
    "    for i in range(3):\n",
    "      for j in range(3):\n",
    "        odl = np.abs(image[x2-1+i,y2-1+j] - srednia)\n",
    "        if (threshold > odl) and (visited[x2-1+i,y2-1+j] == 0):\n",
    "          stack.append((x2-1+i,y2-1+j))\n",
    "          segmented[x2-1+i,y2-1+j] = image[x2-1+i,y2-1+j]\n",
    "        visited[x2-1+i,y2-1+j] = 1\n",
    "  return segmented\n",
    "\n",
    "p = segmentation_lokal(I_knee, 200, 250, 25)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 10)\n",
    "ax.imshow(p, 'gray')\n",
    "ax.set_title('Przed filtracją')\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_1 = cv2.GaussianBlur(I_knee,(5,5),0)\n",
    "plt.imshow(knee_1,'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = segmentation_lokal(knee_1, 200, 250, 60)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 10)\n",
    "ax.imshow(p1, 'gray')\n",
    "ax.axis('off')\n",
    "ax.set_title('Po dodaniu filtracji')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p5 = segmentation_lokal(knee_1, 550, 550, 60)\n",
    "p4 = segmentation_lokal(knee_1, 300, 380, 60)\n",
    "p2 = segmentation_lokal(knee_1, 350, 350, 60)\n",
    "p3 = segmentation_lokal(knee_1, 400, 450, 60)\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.set_size_inches(20, 20)\n",
    "fig.suptitle('Po dodaniu filtracji dla różnych punktów startowych', fontsize=30)\n",
    "axs[0,0].imshow(p4, 'gray')\n",
    "axs[0,0].axis('off')\n",
    "axs[0,1].imshow(p2, 'gray')\n",
    "axs[0,1].axis('off')\n",
    "axs[1,0].imshow(p3, 'gray')\n",
    "axs[1,0].axis('off')\n",
    "axs[1,1].imshow(p5, 'gray')\n",
    "axs[1,1].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
